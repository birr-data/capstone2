{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_profile(df):\n",
    "    '''generate pandas profile'''\n",
    " \n",
    "    profile = ProfileReport(df)   \n",
    "    profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload data\n",
    "\n",
    "#df = pd.read_csv('/Users/Birr/projects/cap2/data/interim/df_aged.csv', low_memory=False)\n",
    "df = pd.read_csv('D:\\cap\\capstone2\\data\\interim\\df_1.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a5d4667a04bb1ac2f734e628110d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=160.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eee236b34f5467dbfc015e4bd48c6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Capstone2\\lib\\site-packages\\pandas_profiling\\visualisation\\plot.py:160: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"RdBu\"))\n",
      "  cmap.set_bad(cmap_bad)\n",
      "D:\\Anaconda\\envs\\Capstone2\\lib\\site-packages\\pandas_profiling\\visualisation\\plot.py:160: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"RdBu\"))\n",
      "  cmap.set_bad(cmap_bad)\n",
      "D:\\Anaconda\\envs\\Capstone2\\lib\\site-packages\\pandas_profiling\\visualisation\\plot.py:160: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"RdBu\"))\n",
      "  cmap.set_bad(cmap_bad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7274200e0a074adfb42c85fddc15a22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render widgets', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_profile(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'INSTR_AME':'INSTRUCT_AME', 'INSTR_ASE':'INSTRUCT_ASE', 'INSTR_GLI':'INSTRUCT_GLI', \n",
    "                    'INSTR_IAIR':'INSTRUCT_IAIR', 'INSTR_SPRT':'INSTRUCT_SPRT', 'INSTR_NONE':'INSTRUCT_NONE',\n",
    "                    'ALL-INST': 'ALL-INSTRUM', 'GLDR-INST':'GLDR-INSTRUCT', 'MAKE-INST':'MAKE-INSTRUCT',\n",
    "                    'MENG-INST':'MENG-INSTRUCT', 'NGHT-INST':'NGHT-INSTRUCT', 'SENG-INST':'SENG-INSTRUCT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after further consideration drop additional columns as they won't be needed in analysis\n",
    "to_drop = ['ac_key', 'ev_id', 'find_key','second_pilot', 'ev_country', 'flt_plan_filed', 'phase_flt_spec', 'CERT_RMPT', \n",
    "           'OTHR_SUAS', 'SIMU-INST', 'SIMU-IRCV', 'SIMU-L24H', 'SIMU-L30D', 'SIMU-L90D', 'SIMU-PIC',\n",
    "           'ROTO-INST', 'ROTO-IRCV', 'ROTO-L24H', 'ROTO-L30D', 'ROTO-L90D', 'ROTO-PIC', 'ROTO-TOTL',\n",
    "           'OTHR_AIRS', 'OTHR_BALL', 'OTHR_GLI', 'OTHR_GYRO', 'OTHR_HELI', 'OTHR_PLFT', 'OTHR_SUAS', 'OTHR_NONE',\n",
    "           'LTA-INST', 'LTA-IRCV', 'LTA-L24H', 'LTA-L30D', 'LTA-L90D', 'LTA-PIC', 'LTA-TOTL', 'Unnamed: 0', \n",
    "           'INSTR_PLFT', 'CERT_FE', 'INSTR_GYRO', 'INSTR_HELI', 'INSTR_IHEL','INSTRUM_HELI', 'INSTR_PLFT',\n",
    "           'INC-NO','REL-NO', 'INSTRUM_PLFT']\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_strip = ['pilot_key', 'ev_date', 'far_part', 'crew_category', 'crew_sex', 'med_certf', 'med_crtf_vldty', \n",
    "            'cat_descript', 'sub_descript', 'sec_descript', 'subsec_descript',  'mod_descript', 'Cause_Factor',\n",
    "            'ev_type', 'mid_air', 'on_ground_collision', 'light_cond', 'ev_highest_injury', 'wx_cond_basic', 'type_fly']\n",
    "\n",
    "for col in to_strip:\n",
    "    df[col] = df[col].str.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ev_date'] = pd.to_datetime(df['ev_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze far_part data (type of operation)\n",
    "df.far_part.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unable to impute UNK values -- drop records\n",
    "df.drop(df[df['far_part'] == 'UNK'].index, inplace = True)\n",
    "df.far_part.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['far_part'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['far_part'] = df['far_part'].fillna('delete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['far_part'] == 'delete'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['far_part'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze crew category\n",
    "df['crew_category'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crew_category'] = df['crew_category'].fillna('UNK')\n",
    "df.crew_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkstu = df[df['crew_category']=='UNK']\n",
    "unkstu.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute student if cert_stu = true\n",
    "stud_cert = df.loc[(df['crew_category'] == 'UNK') & (df['CERT_STU'] == 1.0)]\n",
    "stud_cert.head(0)\n",
    "\n",
    "# none found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using domain knowledge will impute any UNK with less than 60 hour of flt time as Student, otherwise Pilot\n",
    "unk_low_time = df.loc[(df['ALL-TOTL'] <= 60) & (df['crew_category'] == 'UNK')]\n",
    "unk_low_time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no Crew_category UNK records with less that 60 flight hours. Inpute all UNK records as pilots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crew_category'] = df['crew_category'].replace(['UNK'], 'PILOT')\n",
    "df.crew_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crew_sex'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse crew_sex\n",
    "df['crew_sex'] = df['crew_sex'].fillna('UNK')\n",
    "df.crew_sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_certf'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_certf'] = df['med_certf'].fillna('UNK')\n",
    "df['med_certf'] = df['med_certf'].str.strip()\n",
    "df.med_certf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sport pilots do now required a med cert, Basic is not an official medical certificate. Entries may have been done to reflect\n",
    "#other information. Will condense SPRT/BASC to NONE.\n",
    "\n",
    "df['med_certf'] = df['med_certf'].replace(['SPRT', 'BASC'],'NONE')\n",
    "df.med_certf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_certf'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_crtf_vldty'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_crtf_vldty'] = df['med_crtf_vldty'].fillna('UNK')\n",
    "df.med_crtf_vldty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_crtf_vldty'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ev_date'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class3_invalid = df.loc[(df['med_certf'] == 'CL3') & (df['med_crtf_vldty'] == 'UNK')][['pilot_key', \n",
    "                                            'ev_date', 'date_lst_med', 'med_certf', 'med_crtf_vldty']]\n",
    "class3_invalid.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will derive medical certificate validity for UNK values by creating and checking medical expirtion date (last medical +  medical validity time) vs. event date if medical expiration is before event date then UNK will be changed to INVALID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_lst_med'].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace date_last_medical NaN values with future date\n",
    "df['date_lst_med'] = df['date_lst_med'].replace(np.nan, '01/01/2080')\n",
    "df['date_lst_med'] = pd.to_datetime(df['date_lst_med'])\n",
    "df['date_lst_med'].isna().sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN on date last medical replaced to date in the future to indicate no information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create medical expiration date column and populate based on medical type\n",
    "\n",
    "c1_valid_days_under40 = 365 \n",
    "c1_valid_days_over40 =  int(365/2)\n",
    "c2_valid_days = 365\n",
    "c3_valid_days_over40  = 365 * 5\n",
    "c3_valid_days_under40 = 365 * 2\n",
    "\n",
    "med_cert_idx = df.columns.get_loc('med_certf')\n",
    "age_idx = df.columns.get_loc('crew_age')\n",
    "df.insert(9,'medical_exp_date', '')\n",
    "df['medical_exp_date'] = pd.to_datetime(df['medical_exp_date'])\n",
    "last_med_idx = df.columns.get_loc('date_lst_med')\n",
    "\n",
    "for i in range (len(df)):\n",
    "    if (df.iloc[i, med_cert_idx] == 'CL1') & (df.iloc[i, age_idx] >= 40):\n",
    "        df.iloc[i, 9] = df.iloc[i, last_med_idx] + timedelta(c1_valid_days_over40)\n",
    "    elif (df.iloc[i, med_cert_idx] == 'CL1') & (df.iloc[i, age_idx] < 40):\n",
    "        df.iloc[i, 9] = df.iloc[i, last_med_idx] + timedelta(c1_valid_days_under40)\n",
    "    elif (df.iloc[i, med_cert_idx] == 'CL2'): \n",
    "        df.iloc[i, 9] = df.iloc[i, last_med_idx] + timedelta(c2_valid_days)\n",
    "    elif (df.iloc[i, med_cert_idx] == 'CL3') & (df.iloc[i, age_idx] >= 40):\n",
    "        df.iloc[i, 9] = df.iloc[i, last_med_idx] + timedelta(c3_valid_days_over40)\n",
    "    elif (df.iloc[i, med_cert_idx] == 'CL3') & (df.iloc[i, age_idx] < 40):\n",
    "        df.iloc[i, 9] = df.iloc[i, last_med_idx] + timedelta(c3_valid_days_under40)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk = df[df['med_crtf_vldty'] == 'UNK']\n",
    "\n",
    "\n",
    "ev_idx = unk.columns.get_loc('ev_date')\n",
    "exp_idx = unk.columns.get_loc('medical_exp_date')\n",
    "val_idx = unk.columns.get_loc('med_crtf_vldty')\n",
    "\n",
    "for i in range (len(unk)):\n",
    "    if unk.iloc[i, ev_idx] > unk.iloc[i, exp_idx]:\n",
    "        unk.iloc[i, val_idx] = 'INVALID'\n",
    "\n",
    "        \n",
    "unk.med_crtf_vldty.value_counts()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset newly imputed invalid certificates and backfill df\n",
    "\n",
    "inval = unk[unk['med_crtf_vldty'] == 'INVALID']\n",
    "\n",
    "val_idx = df.columns.get_loc('med_crtf_vldty')\n",
    "for i in range (len(inval)):\n",
    "    for r in range (len(df)):\n",
    "        if inval.iloc[i,0] == df.iloc[r,0]:\n",
    "            df.iloc[r, val_idx] = 'INVALID'\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.med_crtf_vldty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined.to_csv('/Users/Birr/projects/cap2/data/interim/df_aged.csv', index=False)\n",
    "df.to_csv('D:\\cap\\capstone2\\data\\interim\\df_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload data\n",
    "\n",
    "#df = pd.read_csv('/Users/Birr/projects/cap2/data/interim/df_aged.csv', low_memory=False)\n",
    "df = pd.read_csv('D:\\cap\\capstone2\\data\\interim\\df_2.csv', low_memory=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Cause_Factor', 'ev_type', 'mid_air', 'on_ground_collision', 'ev_highest_injury']\n",
    "df.drop(to_drop, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wx_cond_basic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wx_cond_basic.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wx_cond_basic'] = df['wx_cond_basic'].fillna('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wx_cond_basic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze type fly\n",
    "df.type_fly.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condense categories & adjust entries for readability\n",
    "\n",
    "rep_dict = {'PUBU':'PUBLIC', 'PUBL':'PUBLIC', 'PUBF':'PUBLIC', 'PUBS':'PUBLIC', 'FERY':'FERRY', 'POSI':'FERRY', 'BUS':'BUSS',\n",
    "            'EXEC':'BUSS', 'OWRK':'OTHRWORK', 'INST':'INSTRUC', 'AOBV':'AERIALOBS', 'FLTS':'FLTTEST', 'ASHO':'ASHOW',\n",
    "            'GLDT':'GLDTTOW', 'BANT':'BANNTOW', 'AAPL':'CROPDUST', 'ADRP':'AIRDROP', 'EXLD':'EXTERNALLOAD'}\n",
    "\n",
    "df.type_fly = df.type_fly.replace(rep_dict)\n",
    "df.type_fly.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined.to_csv('/Users/Birr/projects/cap2/data/interim/df_aged.csv', index=False)\n",
    "df.to_csv('D:\\cap\\capstone2\\data\\interim\\df_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
